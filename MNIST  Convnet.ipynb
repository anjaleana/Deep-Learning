{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import models,layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28,28,1)\n",
    "\n",
    "#load MNIST dataset\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation : We have taken input shape (28,28,1) and loaded the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation : There are 60000 rows and image pixels size is 28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_shape (60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#scale images to the [0,1] range\n",
    "\n",
    "x_train = x_train.astype(\"float32\")/255\n",
    "x_test = x_test.astype(\"float32\")/255\n",
    "\n",
    "#images have shape (28,28,1)\n",
    "x_train = np.expand_dims(x_train,-1)\n",
    "x_test = np.expand_dims(x_test,-1)\n",
    "print(\"x_train_shape\",x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train_samples\n",
      "10000 test_samples\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape[0],\"train_samples\")\n",
    "print(x_test.shape[0],\"test_samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train,num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    tf.keras.Input(shape=input_shape),\n",
    "    layers.Conv2D(32,kernel_size=(3,3),activation = \"relu\"),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Conv2D(64,kernel_size=(3,3),activation = \"relu\"),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes,activation=\"softmax\")\n",
    "\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "epochs= 15\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\",optimizer = \"adam\",metrics= [\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 21s 355us/sample - loss: 0.3482 - acc: 0.8942\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 22s 361us/sample - loss: 0.1068 - acc: 0.9685\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 21s 357us/sample - loss: 0.0816 - acc: 0.9755\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 25s 410us/sample - loss: 0.0691 - acc: 0.9786\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 24s 407us/sample - loss: 0.0587 - acc: 0.9824\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 26s 425us/sample - loss: 0.0536 - acc: 0.9833\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 24s 397us/sample - loss: 0.0496 - acc: 0.9842\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 23s 388us/sample - loss: 0.0467 - acc: 0.9850\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.0425 - acc: 0.9868\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.0413 - acc: 0.9866\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 23s 388us/sample - loss: 0.0378 - acc: 0.9877\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.0367 - acc: 0.9878\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 24s 400us/sample - loss: 0.0338 - acc: 0.9890\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 24s 400us/sample - loss: 0.0336 - acc: 0.9895\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 25s 416us/sample - loss: 0.0319 - acc: 0.9897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bb3f7bd7f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size = batch_size,epochs = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation : Found trained accuracy 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 95us/sample - loss: 0.0238 - acc: 0.9918\n",
      "Test Loss 0.02377357642118004\n",
      "Test accuracy 0.9918\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,y_test)\n",
    "print(\"Test Loss\",score[0])\n",
    "print(\"Test accuracy\",score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation : WE found test accuracy : 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
